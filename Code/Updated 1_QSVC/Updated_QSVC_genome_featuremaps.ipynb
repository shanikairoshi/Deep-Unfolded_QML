{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv1kczzP_bLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit-machine-learning\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer\n",
        "!pip install genomic-benchmarks\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Jqtx2F_VcfG7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit.circuit.library import PauliFeatureMap"
      ],
      "metadata": {
        "id": "GhWY4BVt6-4u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from qiskit.circuit.library import PauliFeatureMap\n",
        "from qiskit.primitives import Sampler\n",
        "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
        "#from qiskit_machine_learning.kernels import FidelityQuantumKernel,QuantumKernel\n",
        "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
        "import time\n",
        "#from qiskit import BasicAer#\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "\n",
        "algorithm_globals.random_seed = 12345\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit.circuit.library import TwoLocal\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "#from qiskit_machine_learning.datasets import iris\n",
        "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from qiskit_machine_learning.algorithms import QSVC\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler # Importing MinMaxScaler from sklearn.preprocessing\n",
        "# Variables to track objective function and learning rate\n",
        "# Set random seed for reproducibility\n",
        "seed = 1376\n",
        "algorithm_globals.random_seed = seed\n",
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "print(f\"Number of samples in the test set: {len(test_set)}\")\n",
        "print(f\"Number of samples in the test set: {len(train_set)}\")\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Filter out sequences that consist entirely of \"N\"\n",
        "filtered_data_set = [sample for sample in data_set if not all(base == 'N' for base in sample[0])]\n",
        "\n",
        "print(f\"Filtered data set size: {len(filtered_data_set)}\")\n",
        "print(\"One sample from the filtered data set:\")\n",
        "print(filtered_data_set[0])\n",
        "\n",
        "word_size = 40\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in filtered_data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "from sklearn.decomposition import PCA\n",
        "# Apply PCA to reduce dimensionality of the scaled data\n",
        "pca = PCA(n_components=2)  # Reduce to 2 components; adjust this number as needed\n",
        "sequences_pca = pca.fit_transform(sequences_scaled)\n",
        "\n",
        "# Update the sequences in np_data_set with the PCA-transformed sequences\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_pca[i]\n",
        "\n",
        "# Shuffle the dataset again after transformation\n",
        "np.random.shuffle(np_data_set)\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "np_train_data = np_data_set[:200]\n",
        "np_test_data = np_data_set[-20:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "# Extract the PCA-transformed sequences and labels\n",
        "train_sequences = np.array([data_point[\"sequence\"] for data_point in np_train_data])\n",
        "train_labels = np.array([data_point[\"label\"] for data_point in np_train_data])\n",
        "\n",
        "test_sequences = np.array([data_point[\"sequence\"] for data_point in np_test_data])\n",
        "test_labels = np.array([data_point[\"label\"] for data_point in np_test_data])\n",
        "\n",
        "print(f\"Shape of reduced train_sequences: {train_sequences.shape}\")\n",
        "print(f\"Shape of reduced test_sequences: {test_sequences.shape}\")\n",
        "\n",
        "# Setup feature map and ansatz for VQC\n",
        "num_features = train_sequences.shape[1]\n",
        "##feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "#ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#features = MinMaxScaler().fit_transform(num_features)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "\n",
        "algorithm_globals.random_seed = 123\n",
        "data_train, data_test, data_train_labels, data_test_labels  = train_test_split(\n",
        "    train_sequences, train_labels, train_size=0.8, random_state=algorithm_globals.random_seed\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rrcnMx42SvW",
        "outputId": "7855574d-2e27-4eaa-a5b5-ccdd2903ddfc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in the test set: 25000\n",
            "Number of samples in the test set: 75000\n",
            "Filtered data set size: 73118\n",
            "One sample from the filtered data set:\n",
            "('TTTCGATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCTTTTGCACCTGAAAGTTTAAAATGTACAAAAGAAAAATGCTAGAATATTCAAGAAAATCGAATTTTCCATCTAAAAATCGCCGCGCCGAGAAGCTTTTGCTCTGTGAGCTCCAAATAGGAAGCCAAAAACTTTCGATTTGAAGCCCAAAGAGCAGCTTTTC', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "TTTCGATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCT 1\n",
            "TTCGATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCTT 2\n",
            "TCGATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCTTT 3\n",
            "CGATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCTTTT 4\n",
            "GATTCAAAAATTGCAAAATTGTTTCAATTAAGCTCTTTTG 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "Length of np_train_data: 200\n",
            "Length of np_test_data: 20\n",
            "Shape of reduced train_sequences: (200, 2)\n",
            "Shape of reduced test_sequences: (20, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code provide QSVC defualt vsualization using featuremap"
      ],
      "metadata": {
        "id": "LM6aXi8rcKRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "objective_func_vals = []\n",
        "learning_rates = []\n",
        "perturbations = []\n",
        "initial_learning_rate = 0.15  # Starting learning rate\n",
        "initial_perturbation = 0.15  # Starting perturbation value\n",
        "momentum = 0.95  # Momentum factor for smoother learning rate adjustments\n",
        "gradient_moving_avg = 0  # Moving average of gradients\n",
        "\n",
        "\n",
        "# Define quantum feature map and ansatz\n",
        "feature_dim = data_train.shape[1]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "feature_map = PauliFeatureMap(feature_dimension=feature_dim, reps=3)\n",
        "\n",
        "sampler = Sampler()\n",
        "\n",
        "fidelity = ComputeUncompute(sampler=sampler)\n",
        "\n",
        "kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
        "print(feature_map.num_qubits)\n",
        "\n",
        "qsvc=QSVC(quantum_kernel=kernel)\n",
        "t0=time.time()\n",
        "qsvc.fit(data_train, data_train_labels)\n",
        "t1 = time.time()\n",
        "print(f\"Time taken for QSVC training PauliFeatureMap: {t1 - t0} seconds\")\n",
        "\n",
        "qsvc_score_test=qsvc.score(data_test, data_test_labels )\n",
        "print(f\"QSVC classification test score PauliFeatureMap: {qsvc_score_test}\")\n",
        "#print(f\"Time taken :{t1-t0}\")\n",
        "\n",
        "\n",
        "qsvc_score_train=qsvc.score(data_train, data_train_labels)\n",
        "print(f\"QSVC classification train score Zzfeaturemap: {qsvc_score_train}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfHkWsNFcJUD",
        "outputId": "fa747786-287c-4176-f06a-2c06a253cd0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-312ee3e1dc4b>:18: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n",
            "  sampler = Sampler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Time taken for QSVC training PauliFeatureMap: 118.81094670295715 seconds\n",
            "QSVC classification test score PauliFeatureMap: 0.9\n",
            "QSVC classification train score Zzfeaturemap: 0.93125\n"
          ]
        }
      ]
    }
  ]
}