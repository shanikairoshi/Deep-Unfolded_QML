{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNI4jGSPZbDtP7oFmkv0u4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/QML-and-Deep-Unfolded_QML/blob/main/DUN_VQC_vs_VQC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znFSByelqq11"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit-machine-learning\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MND6-5A4rW-a",
        "outputId": "ac8128ee-9a4b-4b2e-c9dd-56720e6a3642"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit-machine-learning\n",
            "  Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting qiskit>=0.44 (from qiskit-machine-learning)\n",
            "  Downloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit-algorithms>=0.2.0 (from qiskit-machine-learning)\n",
            "  Downloading qiskit_algorithms-0.3.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (1.3.2)\n",
            "Collecting fastdtw (from qiskit-machine-learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-machine-learning) (71.0.4)\n",
            "Collecting dill>=0.3.4 (from qiskit-machine-learning)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (1.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading stevedore-5.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit-machine-learning) (4.12.2)\n",
            "Collecting symengine>=0.11 (from qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit-machine-learning) (1.16.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit>=0.44->qiskit-machine-learning)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit-machine-learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.7.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit-1.2.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_algorithms-0.3.0-py3-none-any.whl (308 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.6/308.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.3.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.11.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (39.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=512543 sha256=f87d9e2517e1af6e1e8865c3faf31689a68bc554aa88ed9d8a1e69f62f515a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: symengine, rustworkx, pbr, fastdtw, dill, stevedore, qiskit, qiskit-algorithms, qiskit-machine-learning\n",
            "Successfully installed dill-0.3.8 fastdtw-0.3.4 pbr-6.1.0 qiskit-1.2.0 qiskit-algorithms-0.3.0 qiskit-machine-learning-0.7.2 rustworkx-0.15.1 stevedore-5.3.0 symengine-0.11.0\n",
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: qiskit_machine_learning in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: qiskit_algorithms in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.11.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.3.2)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.4)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (71.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.0->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: qiskit>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.13.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (1.13.2)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (4.12.2)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.1.0->qiskit-aer) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.1.0->qiskit-aer) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.1.0->qiskit-aer) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.1.0->qiskit-aer) (1.3.0)\n",
            "Downloading qiskit_aer-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DUN_VQC"
      ],
      "metadata": {
        "id": "nRF8DxGWoETj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "algorithm_globals.random_seed = 3142\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(algorithm_globals.random_seed)\n",
        "\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n",
        "# pylint: disable=unbalanced-tuple-unpacking\n",
        "TRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = (\n",
        "    ad_hoc_data(training_size=20,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                gap=0.3,\n",
        "                one_hot=False)\n",
        ")\n",
        "# ZZfeatureMap for data encoding a\n",
        "# Two Local for variational circuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
        "FEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)\n",
        "VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n",
        "\n",
        "AD_HOC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\n",
        "AD_HOC_CIRCUIT.measure_all()\n",
        "AD_HOC_CIRCUIT.decompose().draw()\n",
        "\n",
        "#We create a function that associates the data to the feature map and the variational parameters to the variational circuit.\n",
        "#This is to ensure that the right parameters\n",
        "#in the circuit are associated with the right quantities.\n",
        "\n",
        "def circuit_instance(data, variational):\n",
        "    \"\"\"Assigns parameter values to `AD_HOC_CIRCUIT`.\n",
        "    Args:\n",
        "        data (list): Data values for the feature map\n",
        "        variational (list): Parameter values for `VAR_FORM`\n",
        "    Returns:\n",
        "        QuantumCircuit: `AD_HOC_CIRCUIT` with parameters assigned\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    parameters = {}\n",
        "    for i, p in enumerate(FEATURE_MAP.ordered_parameters):\n",
        "        parameters[p] = data[i]\n",
        "    for i, p in enumerate(VAR_FORM.ordered_parameters):\n",
        "        parameters[p] = variational[i]\n",
        "    return AD_HOC_CIRCUIT.assign_parameters(parameters)\n",
        "\n",
        "def parity(bitstring):\n",
        "    \"\"\"Returns 1 if parity of `bitstring` is even, otherwise 0.\"\"\"\n",
        "    hamming_weight = sum(int(k) for k in list(bitstring))\n",
        "    return (hamming_weight+1) % 2\n",
        "\n",
        "def label_probability(results):\n",
        "    \"\"\"Converts a dict of bitstrings and their counts,\n",
        "    to parities and their counts\"\"\"\n",
        "    shots = sum(results.values())\n",
        "    probabilities = {0: 0, 1: 0}\n",
        "    for bitstring, counts in results.items():\n",
        "        label = parity(bitstring)\n",
        "        probabilities[label] += counts / shots\n",
        "    return probabilities\n",
        "\n",
        "from qiskit_aer import Aer\n",
        "from qiskit import transpile # Import execute from qiskit\n",
        "\n",
        "\n",
        "def classification_probability(data, variational):\n",
        "    \"\"\"Classify data points using given parameters.\n",
        "    Args:\n",
        "        data (list): Set of data points to classify\n",
        "        variational (list): Parameters for `VAR_FORM`\n",
        "    Returns:\n",
        "        list[dict]: Probability of circuit classifying\n",
        "                    each data point as 0 or 1.\n",
        "    \"\"\"\n",
        "    circuits = [circuit_instance(d, variational) for d in data]\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "    # Transpile and execute each circuit individually\n",
        "    results = []\n",
        "    for circuit in circuits:\n",
        "        t_circuit = transpile(circuit, backend)\n",
        "        result = backend.run(t_circuit).result() # Execute each transpiled circuit\n",
        "        results.append(result)\n",
        "    classification = [\n",
        "        label_probability(result.get_counts()) for result in results] # Get counts from each result\n",
        "    return classification\n",
        "\n",
        "\n",
        "def cross_entropy_loss(classification, expected):\n",
        "    \"\"\"Calculate accuracy of predictions using cross entropy loss.\n",
        "    Args:\n",
        "        classification (dict): Dict where keys are possible classes,\n",
        "                               and values are the probability our\n",
        "                               circuit chooses that class.\n",
        "        expected (int): Correct classification of the data point.\n",
        "\n",
        "    Returns:\n",
        "        float: Cross entropy loss\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    p = classification.get(expected)  # Prob. of correct classification\n",
        "    return -np.log(p + 1e-10)\n",
        "\n",
        "def cost_function(data, labels, variational):\n",
        "    \"\"\"Evaluates performance of our circuit with `variational`\n",
        "    parameters on `data`.\n",
        "\n",
        "    Args:\n",
        "        data (list): List of data points to classify\n",
        "        labels (list): List of correct labels for each data point\n",
        "        variational (list): Parameters to use in circuit\n",
        "\n",
        "    Returns:\n",
        "        float: Cost (metric of performance)\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    classifications = classification_probability(data, variational)\n",
        "    cost = 0\n",
        "    for i, classification in enumerate(classifications):\n",
        "        cost += cross_entropy_loss(classification, labels[i])\n",
        "    cost /= len(data)\n",
        "    return cost\n",
        "\n",
        "class OptimizerLog:  # pylint: disable=too-few-public-methods\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, stepsize, accept):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two.\"\"\"\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)\n",
        "    def save_to_csv(self, filename='optimizer_log_dun.csv'):\n",
        "        \"\"\"Save evaluations and costs to a CSV file.\"\"\"\n",
        "        with open(filename, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Evaluation', 'Cost'])\n",
        "            for evaluation, cost in zip(self.evaluations, self.costs):\n",
        "                writer.writerow([evaluation, cost])\n",
        "        print(f\"Optimizer log saved to {filename}\")\n",
        "\n",
        "# Set up the optimization\n",
        "from qiskit_algorithms.optimizers import GradientDescent\n",
        "#from qiskit.algorithms.optimizers import SPSA\n",
        "log = OptimizerLog()\n",
        "optimizer = GradientDescent(maxiter=1)\n",
        "\n",
        "#initial_point = np.random.random(VAR_FORM.num_parameters)\n",
        "initial_point = np.array([3.28559355, 5.48514978, 5.13099949,\n",
        "                          0.88372228, 4.08885928, 2.45568528,\n",
        "                          4.92364593, 5.59032015, 3.66837805,\n",
        "                          4.84632313, 3.60713748, 2.43546])\n",
        "\n",
        "def objective_function(variational):\n",
        "    \"\"\"Cost function of circuit parameters on training data.\n",
        "    The optimizer will attempt to minimize this.\"\"\"\n",
        "    return cost_function(TRAIN_DATA, TRAIN_LABELS, variational)\n",
        "\n",
        "# Run the optimization\n",
        "\n",
        "# Define a dynamic learning rate function (example: exponential decay)\n",
        "def dynamic_learning_rate(layer, initial_lr=0.1, decay_rate=0.95):\n",
        "    return initial_lr * (decay_rate ** layer)\n",
        "\n",
        "# Deep Unfolding Training\n",
        "num_layers = 200  # Number of layers (iterations) for deep unfolding\n",
        "opt_var = initial_point\n",
        "initial_lr = 0.1  # Initial learning rate\n",
        "\n",
        "for layer in range(num_layers):\n",
        "    # Adjust the learning rate for the current layer\n",
        "    learning_rate = dynamic_learning_rate(layer, initial_lr)\n",
        "\n",
        "    # Reinitialize optimizer with the current learning rate\n",
        "    optimizer = GradientDescent(maxiter=1, learning_rate=learning_rate)\n",
        "\n",
        "    result = optimizer.minimize(objective_function, opt_var)\n",
        "    opt_var = result.x  # Update parameters for the next layer\n",
        "    #log.update(layer, opt_var, result.fun)\n",
        "    log.update(layer, opt_var, result.fun, None, None)\n",
        "\n",
        "    # Print the cost at each iteration\n",
        "    print(f\"Cost after layer {layer + 1}: {result.fun}\")\n",
        "\n",
        "# Final optimized value and cost\n",
        "opt_value = log.costs[-1]\n",
        "opt_var = log.parameters[-1]\n",
        "\n",
        "#result = optimizer.minimize(objective_function, initial_point)\n",
        "\n",
        "#opt_var = result.x\n",
        "#opt_value = result.fun\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(log.evaluations, log.costs)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQFcyQegqwWM",
        "outputId": "ba2f32df-2411-470d-8d74-6a41946f16c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after layer 1: 0.9636964131318582\n",
            "Cost after layer 2: 0.9738448640618362\n",
            "Cost after layer 3: 0.9798325710258405\n",
            "Cost after layer 4: 0.9928041307098789\n",
            "Cost after layer 5: 0.9668795609735928\n",
            "Cost after layer 6: 0.9568618678069889\n",
            "Cost after layer 7: 0.9785935632111148\n",
            "Cost after layer 8: 0.9516789874512362\n",
            "Cost after layer 9: 0.9603729399972651\n",
            "Cost after layer 10: 0.9600914236255615\n",
            "Cost after layer 11: 0.9561426729126279\n",
            "Cost after layer 12: 0.9578022531228021\n",
            "Cost after layer 13: 0.9562192755921151\n",
            "Cost after layer 14: 0.9419563887314016\n",
            "Cost after layer 15: 0.9448223226676863\n",
            "Cost after layer 16: 0.9256490283523731\n",
            "Cost after layer 17: 0.9232820655993438\n",
            "Cost after layer 18: 0.9388092002541104\n",
            "Cost after layer 19: 0.9291450934221019\n",
            "Cost after layer 20: 0.9235492559003682\n",
            "Cost after layer 21: 0.9295959894216506\n",
            "Cost after layer 22: 0.9413669643706177\n",
            "Cost after layer 23: 0.9288640150630803\n",
            "Cost after layer 24: 0.9226454020701007\n",
            "Cost after layer 25: 0.9265962829405734\n",
            "Cost after layer 26: 0.9145601717490793\n",
            "Cost after layer 27: 0.9293204760996112\n",
            "Cost after layer 28: 0.9207011616735155\n",
            "Cost after layer 29: 0.9246051935872057\n",
            "Cost after layer 30: 0.8921562023676366\n",
            "Cost after layer 31: 0.8982433532635092\n",
            "Cost after layer 32: 0.9029329789830907\n",
            "Cost after layer 33: 0.9033022511950817\n",
            "Cost after layer 34: 0.9022303584843707\n",
            "Cost after layer 35: 0.9055754060968791\n",
            "Cost after layer 36: 0.892289438644797\n",
            "Cost after layer 37: 0.8993575194627864\n",
            "Cost after layer 38: 0.8865060213005573\n",
            "Cost after layer 39: 0.8907028465317683\n",
            "Cost after layer 40: 0.8769520864263509\n",
            "Cost after layer 41: 0.8677127312381204\n",
            "Cost after layer 42: 0.8733932489401756\n",
            "Cost after layer 43: 0.8802565462147273\n",
            "Cost after layer 44: 0.8807098268441734\n",
            "Cost after layer 45: 0.870615176868484\n",
            "Cost after layer 46: 0.8577482094093101\n",
            "Cost after layer 47: 0.8657629621732694\n",
            "Cost after layer 48: 0.8540327758293946\n",
            "Cost after layer 49: 0.860686907794278\n",
            "Cost after layer 50: 0.8542774042152115\n",
            "Cost after layer 51: 0.8525401117078054\n",
            "Cost after layer 52: 0.8560544957678677\n",
            "Cost after layer 53: 0.8499888081506128\n",
            "Cost after layer 54: 0.8446592872338977\n",
            "Cost after layer 55: 0.839000308349814\n",
            "Cost after layer 56: 0.8492856264933307\n",
            "Cost after layer 57: 0.8570657833455095\n",
            "Cost after layer 58: 0.8351657458477492\n",
            "Cost after layer 59: 0.8191112981703814\n",
            "Cost after layer 60: 0.8153573863216244\n",
            "Cost after layer 61: 0.8294842462499116\n",
            "Cost after layer 62: 0.8220312105891507\n",
            "Cost after layer 63: 0.8193698938696812\n",
            "Cost after layer 64: 0.8277151532625325\n",
            "Cost after layer 65: 0.8226876910550937\n",
            "Cost after layer 66: 0.8051341918875607\n",
            "Cost after layer 67: 0.8178728545697567\n",
            "Cost after layer 68: 0.81938822708069\n",
            "Cost after layer 69: 0.8159033921205892\n",
            "Cost after layer 70: 0.796155989752863\n",
            "Cost after layer 71: 0.8023088104773828\n",
            "Cost after layer 72: 0.7953883088493485\n",
            "Cost after layer 73: 0.7986517945786026\n",
            "Cost after layer 74: 0.7866783414753205\n",
            "Cost after layer 75: 0.7918079344390078\n",
            "Cost after layer 76: 0.7757022123507\n",
            "Cost after layer 77: 0.7896806375803883\n",
            "Cost after layer 78: 0.7765664639989038\n",
            "Cost after layer 79: 0.7878447177082126\n",
            "Cost after layer 80: 0.779574510220501\n",
            "Cost after layer 81: 0.7737409929712243\n",
            "Cost after layer 82: 0.7710493348918706\n",
            "Cost after layer 83: 0.7772512198101948\n",
            "Cost after layer 84: 0.7700645932736252\n",
            "Cost after layer 85: 0.7720115500224706\n",
            "Cost after layer 86: 0.7809398353439889\n",
            "Cost after layer 87: 0.7676667155621534\n",
            "Cost after layer 88: 0.7747156676985314\n",
            "Cost after layer 89: 0.7787481357380186\n",
            "Cost after layer 90: 0.7641346109903713\n",
            "Cost after layer 91: 0.7834841637215502\n",
            "Cost after layer 92: 0.7851431089620058\n",
            "Cost after layer 93: 0.766927767844902\n",
            "Cost after layer 94: 0.7705818489728559\n",
            "Cost after layer 95: 0.7716699561622414\n",
            "Cost after layer 96: 0.7608213671614517\n",
            "Cost after layer 97: 0.7589857678262086\n",
            "Cost after layer 98: 0.757603645276858\n",
            "Cost after layer 99: 0.7326958187201711\n",
            "Cost after layer 100: 0.7550769854901122\n",
            "Cost after layer 101: 0.7516555597610581\n",
            "Cost after layer 102: 0.7410127181552522\n",
            "Cost after layer 103: 0.7573069085155143\n",
            "Cost after layer 104: 0.7492345394526974\n",
            "Cost after layer 105: 0.7523229073086127\n",
            "Cost after layer 106: 0.7482296547955304\n",
            "Cost after layer 107: 0.7501574556414375\n",
            "Cost after layer 108: 0.7593918216353999\n",
            "Cost after layer 109: 0.7398879911269515\n",
            "Cost after layer 110: 0.7397128108330552\n",
            "Cost after layer 111: 0.7488724013282996\n",
            "Cost after layer 112: 0.7384910726771852\n",
            "Cost after layer 113: 0.7398553710712756\n",
            "Cost after layer 114: 0.736878635715608\n",
            "Cost after layer 115: 0.7366934574155508\n",
            "Cost after layer 116: 0.7326247009777888\n",
            "Cost after layer 117: 0.7362660227911151\n",
            "Cost after layer 118: 0.7419564991882621\n",
            "Cost after layer 119: 0.7293031515391086\n",
            "Cost after layer 120: 0.7356498568852852\n",
            "Cost after layer 121: 0.7400809779491173\n",
            "Cost after layer 122: 0.7399835861311896\n",
            "Cost after layer 123: 0.7391860498870028\n",
            "Cost after layer 124: 0.7375391049929124\n",
            "Cost after layer 125: 0.7304042351928113\n",
            "Cost after layer 126: 0.7310494851049394\n",
            "Cost after layer 127: 0.7317085243613234\n",
            "Cost after layer 128: 0.730710752629294\n",
            "Cost after layer 129: 0.7353200188961122\n",
            "Cost after layer 130: 0.7302462916776873\n",
            "Cost after layer 131: 0.7311996753507357\n",
            "Cost after layer 132: 0.7325870879360655\n",
            "Cost after layer 133: 0.7211560588730752\n",
            "Cost after layer 134: 0.7254919169279912\n",
            "Cost after layer 135: 0.7298341216742592\n",
            "Cost after layer 136: 0.732978986383056\n",
            "Cost after layer 137: 0.7278549669735964\n",
            "Cost after layer 138: 0.7230221291045196\n",
            "Cost after layer 139: 0.7108979429761405\n",
            "Cost after layer 140: 0.7202586368481754\n",
            "Cost after layer 141: 0.6994987122334758\n",
            "Cost after layer 142: 0.7033272323206448\n",
            "Cost after layer 143: 0.7081557852646265\n",
            "Cost after layer 144: 0.7074262509016427\n",
            "Cost after layer 145: 0.6917217548812062\n",
            "Cost after layer 146: 0.7050122823773419\n",
            "Cost after layer 147: 0.7001030436066489\n",
            "Cost after layer 148: 0.6995002109941104\n",
            "Cost after layer 149: 0.6988749384146867\n",
            "Cost after layer 150: 0.6959783655086385\n",
            "Cost after layer 151: 0.6918401576507751\n",
            "Cost after layer 152: 0.6969608146560052\n",
            "Cost after layer 153: 0.6954859847372601\n",
            "Cost after layer 154: 0.6936057840243419\n",
            "Cost after layer 155: 0.6919651645135179\n",
            "Cost after layer 156: 0.6811161380119364\n",
            "Cost after layer 157: 0.6755630461696602\n",
            "Cost after layer 158: 0.6779401722807251\n",
            "Cost after layer 159: 0.6821228781527828\n",
            "Cost after layer 160: 0.6796304344171317\n",
            "Cost after layer 161: 0.6820906046454678\n",
            "Cost after layer 162: 0.6813854579445107\n",
            "Cost after layer 163: 0.6663365318784065\n",
            "Cost after layer 164: 0.6759471439011032\n",
            "Cost after layer 165: 0.6684046562055608\n",
            "Cost after layer 166: 0.6747740469947975\n",
            "Cost after layer 167: 0.6740731950428716\n",
            "Cost after layer 168: 0.6698591173272535\n",
            "Cost after layer 169: 0.6633693668044532\n",
            "Cost after layer 170: 0.6711361372498926\n",
            "Cost after layer 171: 0.6794615555621225\n",
            "Cost after layer 172: 0.6652103340616494\n",
            "Cost after layer 173: 0.6657600118526419\n",
            "Cost after layer 174: 0.6754774260130987\n",
            "Cost after layer 175: 0.6646507606002243\n",
            "Cost after layer 176: 0.6704654648729866\n",
            "Cost after layer 177: 0.6682449312707583\n",
            "Cost after layer 178: 0.6617428692704755\n",
            "Cost after layer 179: 0.6639884830396335\n",
            "Cost after layer 180: 0.6657393888424108\n",
            "Cost after layer 181: 0.6601273842190442\n",
            "Cost after layer 182: 0.6530855688124018\n",
            "Cost after layer 183: 0.6619688804286155\n",
            "Cost after layer 184: 0.6498583617343986\n",
            "Cost after layer 185: 0.6525372332786354\n",
            "Cost after layer 186: 0.6453341952761661\n",
            "Cost after layer 187: 0.6521788922829612\n",
            "Cost after layer 188: 0.6458450201628589\n",
            "Cost after layer 189: 0.6494952415857266\n",
            "Cost after layer 190: 0.6502596877125322\n",
            "Cost after layer 191: 0.651844619573876\n",
            "Cost after layer 192: 0.6479024369189361\n",
            "Cost after layer 193: 0.6429313530623185\n",
            "Cost after layer 194: 0.6373541882853131\n",
            "Cost after layer 195: 0.6414535348505762\n",
            "Cost after layer 196: 0.6417596782696631\n",
            "Cost after layer 197: 0.6325293027029206\n",
            "Cost after layer 198: 0.6285135644075177\n",
            "Cost after layer 199: 0.6261529012124869\n",
            "Cost after layer 200: 0.6283427623606256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VQC"
      ],
      "metadata": {
        "id": "6YONgaRioGbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_algorithms.utils import algorithm_globals\n",
        "algorithm_globals.random_seed = 3142\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(algorithm_globals.random_seed)\n",
        "\n",
        "from qiskit_machine_learning.datasets import ad_hoc_data\n",
        "# pylint: disable=unbalanced-tuple-unpacking\n",
        "TRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = (\n",
        "    ad_hoc_data(training_size=20,\n",
        "                test_size=5,\n",
        "                n=2,\n",
        "                gap=0.3,\n",
        "                one_hot=False)\n",
        ")\n",
        "# ZZfeatureMap for data encoding a\n",
        "# Two Local for variational circuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
        "FEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)\n",
        "VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n",
        "\n",
        "AD_HOC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\n",
        "AD_HOC_CIRCUIT.measure_all()\n",
        "AD_HOC_CIRCUIT.decompose().draw()\n",
        "\n",
        "#We create a function that associates the data to the feature map and the variational parameters to the variational circuit.\n",
        "#This is to ensure that the right parameters\n",
        "#in the circuit are associated with the right quantities.\n",
        "\n",
        "def circuit_instance(data, variational):\n",
        "    \"\"\"Assigns parameter values to `AD_HOC_CIRCUIT`.\n",
        "    Args:\n",
        "        data (list): Data values for the feature map\n",
        "        variational (list): Parameter values for `VAR_FORM`\n",
        "    Returns:\n",
        "        QuantumCircuit: `AD_HOC_CIRCUIT` with parameters assigned\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    parameters = {}\n",
        "    for i, p in enumerate(FEATURE_MAP.ordered_parameters):\n",
        "        parameters[p] = data[i]\n",
        "    for i, p in enumerate(VAR_FORM.ordered_parameters):\n",
        "        parameters[p] = variational[i]\n",
        "    return AD_HOC_CIRCUIT.assign_parameters(parameters)\n",
        "\n",
        "def parity(bitstring):\n",
        "    \"\"\"Returns 1 if parity of `bitstring` is even, otherwise 0.\"\"\"\n",
        "    hamming_weight = sum(int(k) for k in list(bitstring))\n",
        "    return (hamming_weight+1) % 2\n",
        "\n",
        "def label_probability(results):\n",
        "    \"\"\"Converts a dict of bitstrings and their counts,\n",
        "    to parities and their counts\"\"\"\n",
        "    shots = sum(results.values())\n",
        "    probabilities = {0: 0, 1: 0}\n",
        "    for bitstring, counts in results.items():\n",
        "        label = parity(bitstring)\n",
        "        probabilities[label] += counts / shots\n",
        "    return probabilities\n",
        "\n",
        "from qiskit_aer import Aer\n",
        "from qiskit import transpile # Import execute from qiskit\n",
        "\n",
        "\n",
        "def classification_probability(data, variational):\n",
        "    \"\"\"Classify data points using given parameters.\n",
        "    Args:\n",
        "        data (list): Set of data points to classify\n",
        "        variational (list): Parameters for `VAR_FORM`\n",
        "    Returns:\n",
        "        list[dict]: Probability of circuit classifying\n",
        "                    each data point as 0 or 1.\n",
        "    \"\"\"\n",
        "    circuits = [circuit_instance(d, variational) for d in data]\n",
        "    backend = Aer.get_backend('qasm_simulator')\n",
        "    # Transpile and execute each circuit individually\n",
        "    results = []\n",
        "    for circuit in circuits:\n",
        "        t_circuit = transpile(circuit, backend)\n",
        "        result = backend.run(t_circuit).result() # Execute each transpiled circuit\n",
        "        results.append(result)\n",
        "    classification = [\n",
        "        label_probability(result.get_counts()) for result in results] # Get counts from each result\n",
        "    return classification\n",
        "\n",
        "\n",
        "def cross_entropy_loss(classification, expected):\n",
        "    \"\"\"Calculate accuracy of predictions using cross entropy loss.\n",
        "    Args:\n",
        "        classification (dict): Dict where keys are possible classes,\n",
        "                               and values are the probability our\n",
        "                               circuit chooses that class.\n",
        "        expected (int): Correct classification of the data point.\n",
        "\n",
        "    Returns:\n",
        "        float: Cross entropy loss\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    p = classification.get(expected)  # Prob. of correct classification\n",
        "    return -np.log(p + 1e-10)\n",
        "\n",
        "def cost_function(data, labels, variational):\n",
        "    \"\"\"Evaluates performance of our circuit with `variational`\n",
        "    parameters on `data`.\n",
        "\n",
        "    Args:\n",
        "        data (list): List of data points to classify\n",
        "        labels (list): List of correct labels for each data point\n",
        "        variational (list): Parameters to use in circuit\n",
        "\n",
        "    Returns:\n",
        "        float: Cost (metric of performance)\n",
        "    \"\"\"\n",
        "    # pylint: disable=invalid-name\n",
        "    classifications = classification_probability(data, variational)\n",
        "    cost = 0\n",
        "    for i, classification in enumerate(classifications):\n",
        "        cost += cross_entropy_loss(classification, labels[i])\n",
        "    cost /= len(data)\n",
        "    return cost\n",
        "\n",
        "class OptimizerLog:  # pylint: disable=too-few-public-methods\n",
        "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
        "    def __init__(self):\n",
        "        self.evaluations = []\n",
        "        self.parameters = []\n",
        "        self.costs = []\n",
        "    def update(self, evaluation, parameter, cost, _stepsize):\n",
        "        \"\"\"Save intermediate results. Optimizer passes five values\n",
        "        but we ignore the last two.\"\"\"\n",
        "        self.evaluations.append(evaluation)\n",
        "        self.parameters.append(parameter)\n",
        "        self.costs.append(cost)\n",
        "\n",
        "        # Print the cost for each iteration\n",
        "        print(f\"Iteration {evaluation}: Cost = {cost}\")\n",
        "\n",
        "    def save_to_csv(self, filename='optimizer_log_default.csv'):\n",
        "        \"\"\"Save evaluations and costs to a CSV file.\"\"\"\n",
        "        with open(filename, mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(['Evaluation', 'Cost'])\n",
        "            for evaluation, cost in zip(self.evaluations, self.costs):\n",
        "                writer.writerow([evaluation, cost])\n",
        "        print(f\"Optimizer log saved to {filename}\")\n",
        "\n",
        "# Set up the optimization\n",
        "from qiskit_algorithms.optimizers import GradientDescent\n",
        "#from qiskit.algorithms.optimizers import SPSA\n",
        "log = OptimizerLog()\n",
        "optimizer = GradientDescent(maxiter=100, callback=log.update)\n",
        "\n",
        "#initial_point = np.random.random(VAR_FORM.num_parameters)\n",
        "initial_point = np.array([3.28559355, 5.48514978, 5.13099949,\n",
        "                          0.88372228, 4.08885928, 2.45568528,\n",
        "                          4.92364593, 5.59032015, 3.66837805,\n",
        "                          4.84632313, 3.60713748, 2.43546])\n",
        "\n",
        "def objective_function(variational):\n",
        "    \"\"\"Cost function of circuit parameters on training data.\n",
        "    The optimizer will attempt to minimize this.\"\"\"\n",
        "    return cost_function(TRAIN_DATA, TRAIN_LABELS, variational)\n",
        "\n",
        "# Run the optimization\n",
        "result = optimizer.minimize(objective_function, initial_point)\n",
        "\n",
        "opt_var = result.x\n",
        "opt_value = result.fun\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "plt.plot(log.evaluations, log.costs)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhBcmlHEoKxk",
        "outputId": "df6ae9c1-a896-4f27-dcd4-7c0d4aa5790d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 13: Cost = 0.9772606059270373\n",
            "Iteration 26: Cost = 0.9733547915098353\n",
            "Iteration 39: Cost = 0.9814252700371879\n",
            "Iteration 52: Cost = 0.9664318591952034\n",
            "Iteration 65: Cost = 0.964691212571401\n",
            "Iteration 78: Cost = 0.9515558038975698\n",
            "Iteration 91: Cost = 0.9495238360968274\n",
            "Iteration 104: Cost = 0.9498356941381306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Modifications:\n",
        "Custom Training Loop: The training loop explicitly iterates through num_layers, where each layer represents one step of the optimizer.\n",
        "\n",
        "Optimizer with Maxiter=1: The optimizer is set to perform only one iteration per call, corresponding to one layer in the deep unfolding process.\n",
        "\n",
        "Parameter Update per Layer: After each layer, the parameters are updated, and the optimizer’s performance is logged."
      ],
      "metadata": {
        "id": "KpCxCGlL9uZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Update the Optimization Process\n",
        "Instead of using the standard GradientDescent optimizer for a fixed number of iterations, we will define a custom training loop that corresponds to layers in the deep unfolding process.\n",
        "2. Layer-wise Training\n",
        "Each layer in the deep unfolding will correspond to a single step of the optimizer. After each layer, you will update the parameters of the quantum circuit.\n",
        "3. Controlled Layer Count\n",
        "We will explicitly control the number of layers (iterations) in the deep unfolding process."
      ],
      "metadata": {
        "id": "Gnq9K5sY-RmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The deep unfolding approach differs from the normal process of training a Variational Quantum Classifier (VQC) in several key ways:\n",
        "\n",
        "1. Optimization Approach\n",
        "Normal Process: In the standard VQC training, you typically use a classical optimizer (like gradient descent, SPSA, or COBYLA) that iteratively adjusts the parameters of the quantum circuit to minimize a loss function. This process continues until the optimizer converges to a solution or until a predefined number of iterations is reached.\n",
        "Deep Unfolding: Instead of running an optimizer to convergence, deep unfolding transforms the iterative optimization process into a sequence of layers. Each layer represents a single iteration of the optimization algorithm, and you explicitly design the process to unfold over a fixed number of layers. The parameters are updated layer by layer, mimicking the steps of the optimization algorithm.\n",
        "2. Training Dynamics\n",
        "Normal Process: The optimizer dynamically adjusts the parameters based on the gradient (or some other update rule) in each iteration, potentially requiring many iterations to find a good solution. The focus is on finding a global or local minimum by iterating until convergence.\n",
        "Deep Unfolding: The training is constrained to a fixed number of layers, each corresponding to an iteration of the optimization algorithm. This approach can potentially provide faster convergence and more structured training dynamics by explicitly controlling the number of updates, effectively limiting the optimization process.\n",
        "3. Parameter Updates\n",
        "Normal Process: Parameter updates occur continuously across the entire optimization process, with the algorithm iterating until a stopping criterion is met (e.g., convergence tolerance, maximum iterations).\n",
        "Deep Unfolding: Parameters are updated in a discrete, layer-wise manner, with the number of updates directly tied to the number of layers. This can lead to a more structured and potentially more interpretable model, as each layer corresponds to a specific iteration of the underlying optimization process.\n",
        "4. Model Structure\n",
        "Normal Process: The model structure is primarily defined by the quantum circuit (the ansatz), and the optimization process is treated as an external method to find the best parameters for this structure.\n",
        "Deep Unfolding: The model structure is explicitly tied to the optimization process, where the number of layers in the model corresponds directly to the number of iterations in the optimization algorithm. This creates a more integrated model where the architecture and training process are closely intertwined.\n",
        "5. Flexibility and Interpretability\n",
        "Normal Process: The optimization process is generally flexible, with the ability to use various optimizers and dynamically adjust learning rates or other hyperparameters. However, the process may be less interpretable since the training dynamics are not explicitly modeled.\n",
        "Deep Unfolding: The process is more structured and potentially more interpretable, as each layer corresponds to a known step in an optimization algorithm. This structure can lead to better insights into how the model is learning, although it may reduce flexibility compared to the normal process.\n",
        "6. Training Efficiency\n",
        "Normal Process: Training efficiency depends on the choice of optimizer and the complexity of the quantum circuit. Some optimizers might require many iterations to converge, leading to longer training times.\n",
        "Deep Unfolding: By fixing the number of layers and tying each layer to a specific iteration, deep unfolding can potentially improve training efficiency, as it imposes a structured limit on the number of updates. This can lead to faster training, especially in scenarios where a full iterative optimization might be overkill.\n",
        "7. Application of Regularization\n",
        "Normal Process: Regularization methods can be applied in a post-hoc manner, adjusting the loss function or the parameters during the optimization process to prevent overfitting.\n",
        "Deep Unfolding: Regularization can be built into the deep unfolding process, where specific layers or steps in the unfolding can be designed to introduce regularization effects. This can lead to a more integrated and potentially more effective regularization strategy.\n",
        "Summary\n",
        "In essence, the deep unfolding approach imposes a fixed structure on the optimization process, transforming it from a potentially lengthy iterative procedure into a structured, layer-wise training process. This can lead to improvements in training efficiency, interpretability, and potentially even performance, depending on the specific application and problem at hand. However, it also requires careful design and might reduce flexibility compared to the standard approach."
      ],
      "metadata": {
        "id": "5D_nZN6VBWho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "769E1et0BYQP"
      }
    }
  ]
}